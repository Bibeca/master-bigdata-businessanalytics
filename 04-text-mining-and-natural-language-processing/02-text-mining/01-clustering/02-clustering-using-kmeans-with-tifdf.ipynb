{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining - Clustering using `K-Means` with `tfidf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply clustering using `K-Means` with `tfidf` vectorizer, we are going to use the example into that [URL](http://scikit-learn.org/stable/auto_examples/text/document_clustering.html). That example use a vectorizer to getting the `tfidf` of all words in a document. This vectorizer is `TfidfVectorizer`.\n",
    "\n",
    "We are going to use the [20newgroups](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#newsgroups) corpus and select two group: `alt.atheis` and `sci.space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the corpus of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'sci.space']\n",
      "\n",
      "1786 documents\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'sci.space'\n",
    "]\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "print()\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()\n",
    "\n",
    "# Get the labels of each document\n",
    "labels = dataset.target\n",
    "# Get the true k-clusters\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Texts vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "n_samples: 1786, n_features: 15500\n"
     ]
    }
   ],
   "source": [
    "n_features = 100\n",
    "use_idf = True\n",
    "\n",
    "# Create the tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, #max_features = n_features,\n",
    "                             stop_words='english', use_idf=use_idf)\n",
    "# Vectorize dataset\n",
    "vec_dataset = vectorizer.fit_transform(dataset.data)\n",
    "print(vec_dataset.toarray())\n",
    "print(\"n_samples: %d, n_features: %d\" % vec_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Texts clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 3446.181\n",
      "Iteration  1, inertia 1741.009\n",
      "Iteration  2, inertia 1735.972\n",
      "Iteration  3, inertia 1733.070\n",
      "Iteration  4, inertia 1732.291\n",
      "Iteration  5, inertia 1732.167\n",
      "Iteration  6, inertia 1732.152\n",
      "Converged at iteration 6: center shift 0.000000e+00 within tolerance 6.317085e-09\n",
      "Fit time: 0.710s\n",
      "\n",
      "Print the clusters:\n",
      "Cluster 0: god com keith people sgi don livesey atheists say think\n",
      "Cluster 1: space nasa henry access com toronto digex gov alaska pat\n"
     ]
    }
   ],
   "source": [
    "# Apply the KMeans algorithm\n",
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1, verbose=True, random_state=1)\n",
    "\n",
    "# Get time 0\n",
    "t0 = time()\n",
    "\n",
    "# Fit the KMeans algorithm with vectorized texts.\n",
    "km.fit(vec_dataset)\n",
    "print(\"Fit time: %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Print the clusters\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print (\"Print the clusters:\")\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "          print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clustering quality measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.902\n",
      "Completeness: 0.906\n",
      "V-measure: 0.904\n"
     ]
    }
   ],
   "source": [
    "# Calculate the clustering goodness with: homogeneity_score, completeness_score and v_measure_score\n",
    "\n",
    "# A cluster is homogeneous if its all elements contains members of the same class\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "\n",
    "# A class is compelete if its all elements belong to the same cluster\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "\n",
    "# V-measure is the weighted average of the last two metrics\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality data are good with our dataset (1550 elements split on 2 clusters). The homogeneity is high (0.902) which indicates the elements which compose each cluster are very similar between them. In a clustering process, this fact is searched and, in addition, that the different clusters are as more heterogeneous as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use the trained KMeans to classify others texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's classify 2 new texts:\n",
      "\n",
      "TEXT 1 (about the atheism in Arabia Saudí):\n",
      " ['Atheism remains one of the most extreme taboos in Saudi Arabia. It is a red line that no one can cross. Atheists in Saudi Arabia have been suffering from imprisonment, maginalisation, slander, ostracisation and even execution. Atheists are considered terrorists. Efforts for normalisation between those who believe and those who don’t remain bleak in the kingdom. Despite constant warnings of Saudi religious authorities of “the danger of atheism,” many citizens in the kingdom are turning their backs on Islam. The Saudi dehumanizing strict laws in the name of Islam, easy access to information and mass communication are the primary driving forces pushing Saudis to leave religion. Unfortunately, those who explicitly do, find themselves harshly punished or forced to live dual lives.']\n",
      "\n",
      "TEXT 2 (about the arrival of man on the moon):\n",
      " ['The man speaking was Neil Armstrong, whose brevity marked the moment when the lunar module Eagle completed its perilous journey from Apollo 11 and touched down upon the surface of the Moon. The world waited on tenterhooks as hour after hour of checks were carried out. Finally, the hatch opened, and Armstrong descended the ladder to become the first human to set foot on the Moon, with the now immortal words: That’s one small step for man, one giant leap for mankind.There cannot be many who have not, however briefly, glanced at the Moon and wondered what it must have been like for Armstrong to look back at the blue and green planet we call home. The landing may have happened almost five decades ago, but space exploration has not lost its allure. Even those of us who were not born when this momentous event unfolded are caught in its gravitational pull. With this in mind, it seems only fitting that Sotheby’s New York has decided to host its first space exploration auction, featuring memorabilia from American-led space missions, exactly 48 years to the day after Apollo 11’s lunar landing.']\n",
      "\n",
      "tfAtheism: [[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "tfSpace: [[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "Text 1 prediction (atheism): Cluster 0\n",
      "Text 2 prediction (space): Cluster 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's classify 2 new texts:\")\n",
    "print ()\n",
    "\n",
    "# Set the new texts:\n",
    "atheism = [\"Atheism remains one of the most extreme taboos in Saudi Arabia. It is a red line that no one can cross. Atheists in Saudi Arabia have been suffering from imprisonment, maginalisation, slander, ostracisation and even execution. Atheists are considered terrorists. Efforts for normalisation between those who believe and those who don’t remain bleak in the kingdom. Despite constant warnings of Saudi religious authorities of “the danger of atheism,” many citizens in the kingdom are turning their backs on Islam. The Saudi dehumanizing strict laws in the name of Islam, easy access to information and mass communication are the primary driving forces pushing Saudis to leave religion. Unfortunately, those who explicitly do, find themselves harshly punished or forced to live dual lives.\"]\n",
    "space = [\"The man speaking was Neil Armstrong, whose brevity marked the moment when the lunar module Eagle completed its perilous journey from Apollo 11 and touched down upon the surface of the Moon. The world waited on tenterhooks as hour after hour of checks were carried out. Finally, the hatch opened, and Armstrong descended the ladder to become the first human to set foot on the Moon, with the now immortal words: That’s one small step for man, one giant leap for mankind.There cannot be many who have not, however briefly, glanced at the Moon and wondered what it must have been like for Armstrong to look back at the blue and green planet we call home. The landing may have happened almost five decades ago, but space exploration has not lost its allure. Even those of us who were not born when this momentous event unfolded are caught in its gravitational pull. With this in mind, it seems only fitting that Sotheby’s New York has decided to host its first space exploration auction, featuring memorabilia from American-led space missions, exactly 48 years to the day after Apollo 11’s lunar landing.\"]\n",
    "\n",
    "# Vectorize the texts\n",
    "tfAtheism =  vectorizer.transform(atheism)\n",
    "tfSpace =  vectorizer.transform(space)\n",
    "\n",
    "# Print the texts\n",
    "print (\"TEXT 1 (about the atheism in Arabia Saudí):\\n\", atheism)\n",
    "print ()\n",
    "print (\"TEXT 2 (about the arrival of man on the moon):\\n\", space)\n",
    "print ()\n",
    "\n",
    "# Print the tfMatrix\n",
    "print (\"tfAtheism:\",tfAtheism.toarray() )\n",
    "print (\"tfSpace:\",tfSpace.toarray() )\n",
    "print ()\n",
    "\n",
    "# Make the predition and print it\n",
    "atheismPrediction = km.predict(tfAtheism)[0]\n",
    "print (\"Text 1 prediction (atheism): Cluster\", atheismPrediction)\n",
    "spacePrediction = km.predict(tfSpace)[0]\n",
    "print (\"Text 2 prediction (space): Cluster\", spacePrediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the our system has classify the new text correctly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
