{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical case - Food Orders - Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all details and explications of the practical case analysis. [01-food-orders](./01-food-orders.ipynb) notebook only contains the function required by that statement with all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement (written in spanish) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio se va a imaginar que se trabaja para una empresa de envíos de comida, presente\n",
    "en todo el territorio nacional, con miles de pedidos cada día. Dicha empresa tiene un fichero histórico\n",
    "con todas las peticiones de comida que los clientes han realizado mediante el chat de su web en los\n",
    "últimos meses. Necesitan analizar en tiempo real qué comidas están pidiendo los usuarios y qué\n",
    "ingredientes tenían, ya que en la cadena de stock de alimentos es necesario realizar una previsión para\n",
    "no quedarse sin platos cocinados. \n",
    "\n",
    "Se ha calculado que el impacto en las ventas cada vez que uno de\n",
    "los platos deja de estar disponible es del 7% de pérdidas en esa semana, debido al abandono de la web\n",
    "de pedidos por parte del cliente. Por tanto, es de vital importancia poder realizar automáticamente\n",
    "estimaciones al respecto.\n",
    "\n",
    "El objetivo es programar una función que reciba como input un texto de usuario y devuelva los\n",
    "fragmentos de texto (chunks) que hagan referencia a las comidas y cantidades que ha solicitado. No es\n",
    "necesario, ni es el objetivo de este ejercicio, construir un clasificador de intención previo a esta\n",
    "función, sino simplemente una función que presuponemos recibe una frase con la intención\n",
    "`Pedir_comida`. Tampoco es objetivo normalizar la salida (por ej.: no es necesario convertir 'tres' a '3'\n",
    "ni 'pizzas' a 'pizza'). Es, por tanto, un ejercicio de mínimos.\n",
    "\n",
    "    Por ejemplo: “quiero 3 bocadillos de anchoas y 2 pizzas” →\n",
    "    [\n",
    "        {comida:'bocadillo', ingrediente:'anchoas', cantidad:3},\n",
    "        {comida:'pizza', ingrediente:'null', cantidad:2}\n",
    "    ]\n",
    "    \n",
    "Por tanto, la salida de la función será un array con diccionarios de 2 elementos (`comida` y `cantidad`).\n",
    "Cuando una cantidad no sea detectada, se pondrá su valor a '1' como valor por defecto.\n",
    "\n",
    "Se deberá comenzar la práctica por el nivel más básico de dificultad (`RegexParser`) y, en caso de\n",
    "conseguirlo, añadir los siguientes niveles de forma sucesiva. De esta forma, el entregable contendrá\n",
    "todas y cada una de las tres formas de solucionar el problema. No basta, por tanto, con incluir, por\n",
    "ejemplo, únicamente un `NaiveBayesClassifier`, hay que incluir también las otras dos formas si se\n",
    "quiere obtener la máxima puntuación. Se trata simplemente de una práctica y, por tanto, no se espera\n",
    "como resultado un sistema de alta precisión listo para usar en producción, sino simplemente una\n",
    "aproximación básica que permita ejecutar las tres formas de resolver el problema.\n",
    "\n",
    "Este ejercicio hay que hacerlo con textos de entrenamiento en español, pero teniendo en cuenta que\n",
    "la precisión de los POS taggers en castellano de NLTK es muy mala. Por tanto, el alumno no debe\n",
    "frustrarse por no obtener buenos resultados, como hemos dicho anteriormente se trata simplemente de\n",
    "un ejercicio teórico y podemos suponer que, con un mejor analizador, podríamos obtener mejores\n",
    "resultados.\n",
    "\n",
    "Para llevar a cabo la práctica, deberá construirse una cadena NLP con NLTK, con los siguientes\n",
    "elementos:\n",
    "    - segmentación de frases,\n",
    "    - tokenización,\n",
    "    - POS tagger (analizador mofológico para el español).\n",
    "\n",
    "A continuación, los POS tags obtenidos serán usados por el `RegexParser`, el `UnigramParser`, el\n",
    "`BigramParser` y el `NaiveBayesClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import NLTK and Spanish CESS Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "# Load all tagged sentences of Spanish CESS corpus\n",
    "sents = cess_esp.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagger training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making the several versions required by that practical case, we have to train a POS tagger for Spanish CESS corpus. For that, we are going to use the `HiddenMarkovModelTagger` tagger, because that tagger is more complete than `UnigramTagger`, `BigramTagger` and `TrigramTagger` taggers.\n",
    "\n",
    "At first, we will make the train (90%) and test (10%) datasets and evaluate if the trained model is not overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "for i in range(len(sents)) :\n",
    "    if i % 10 :\n",
    "        training.append(sents[i])\n",
    "    else :\n",
    "        testing.append(sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sents) = 6030\n",
      "len(training) = 5427\n",
      "len(testing) = 603\n"
     ]
    }
   ],
   "source": [
    "print('len(sents) =', len(sents))\n",
    "print('len(training) =', len(training))\n",
    "print('len(testing) =', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "# Import HiddenMarkovModelTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "# Create the Spanish POS tagger using HMM Tagger\n",
    "spanish_pos_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "# Evaluate that tagger\n",
    "print('Evaluation:', spanish_pos_tagger.evaluate(testing)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, that model is not overfitting and its evaluation is good. So, we will use that POS tagger for our tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Part-of-Speech Tagset of Spanish CESS Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using `RegexParser`, we have to know how are the Spanish tags provided by our tagger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set which will contain all tags\n",
    "tagset = set()\n",
    "\n",
    "for sent in sents :\n",
    "    tagset.update([ tag for (word, tag) in sent ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Faa', 'Fat', 'Fc', 'Fd', 'Fe', 'Fg', 'Fh', 'Fia', 'Fit', 'Fp', 'Fpa', 'Fpt', 'Fs', 'Fx', 'Fz', 'I', 'W', 'X', 'Y', 'Z', 'Zm', 'Zp', 'ao0fp0', 'ao0fs0', 'ao0mp0', 'ao0ms0', 'aq00000', 'aq0cn0', 'aq0cp0', 'aq0cs0', 'aq0fp0', 'aq0fpp', 'aq0fs0', 'aq0fsp', 'aq0mp0', 'aq0mpp', 'aq0ms0', 'aq0msp', 'cc', 'cs', 'da0fp0', 'da0fs0', 'da0mp0', 'da0ms0', 'da0ns0', 'dd0cp0', 'dd0cs0', 'dd0fp0', 'dd0fs0', 'dd0mp0', 'dd0ms0', 'de0cn0', 'di0cp0', 'di0cs0', 'di0fp0', 'di0fs0', 'di0mp0', 'di0ms0', 'dn0cp0', 'dn0cs0', 'dn0fp0', 'dn0fs0', 'dn0mp0', 'dn0ms0', 'dp1cps', 'dp1css', 'dp1fpp', 'dp1fsp', 'dp1mpp', 'dp1msp', 'dp1mss', 'dp2cps', 'dp2css', 'dp3cp0', 'dp3cs0', 'dp3fs0', 'dp3mp0', 'dp3ms0', 'dt0cn0', 'dt0fs0', 'dt0ms0', 'i', 'nc00000', 'nccn000', 'nccp000', 'nccs000', 'ncfn000', 'ncfp000', 'ncfs000', 'ncmn000', 'ncmp000', 'ncms000', 'np00000', 'np0000a', 'np0000l', 'np0000o', 'np0000p', 'p0000000', 'p010p000', 'p010s000', 'p020s000', 'p0300000', 'pd0cp000', 'pd0cs000', 'pd0fp000', 'pd0fs000', 'pd0mp000', 'pd0ms000', 'pd0ns000', 'pe000000', 'pi0cp000', 'pi0cs000', 'pi0fp000', 'pi0fs000', 'pi0mp000', 'pi0ms000', 'pn0cp000', 'pn0fp000', 'pn0fs000', 'pn0mp000', 'pn0ms000', 'pp1cp000', 'pp1cs000', 'pp1csn00', 'pp1cso00', 'pp1mp000', 'pp2cp000', 'pp2cp00p', 'pp2cs000', 'pp2cs00p', 'pp2csn00', 'pp2cso00', 'pp3cn000', 'pp3cna00', 'pp3cno00', 'pp3cpa00', 'pp3cpd00', 'pp3csa00', 'pp3csd00', 'pp3fp000', 'pp3fpa00', 'pp3fs000', 'pp3fsa00', 'pp3mp000', 'pp3mpa00', 'pp3ms000', 'pp3msa00', 'pp3ns000', 'pr000000', 'pr0cn000', 'pr0cp000', 'pr0cs000', 'pr0fp000', 'pr0fs000', 'pr0mp000', 'pr0ms000', 'pt000000', 'pt0cp000', 'pt0cs000', 'pt0mp000', 'pt0ms000', 'px1fp0p0', 'px1fs0p0', 'px1mp0p0', 'px1ms0p0', 'px2fs0s0', 'px3fs000', 'px3mp000', 'px3ms000', 'px3ns000', 'rg', 'rn', 'sn-SUJ', 'sn.co-SUJ', 'sn.e', 'sn.e-ATR', 'sn.e-CD', 'sn.e-SUJ', 'sn.e.1n-SUJ', 'spcms', 'sps00', 'vag0000', 'vaic1p0', 'vaic3p0', 'vaic3s0', 'vaif1p0', 'vaif2s0', 'vaif3p0', 'vaif3s0', 'vaii1p0', 'vaii1s0', 'vaii2s0', 'vaii3p0', 'vaii3s0', 'vaip1p0', 'vaip1s0', 'vaip2p0', 'vaip2s0', 'vaip3p0', 'vaip3s0', 'vais3s0', 'vam02s0', 'vam03s0', 'van0000', 'vap00sm', 'vasi1p0', 'vasi1s0', 'vasi3p0', 'vasi3s0', 'vasp1s0', 'vasp3p0', 'vasp3s0', 'vmg0000', 'vmic1p0', 'vmic1s0', 'vmic2s0', 'vmic3p0', 'vmic3s0', 'vmif1p0', 'vmif1s0', 'vmif2s0', 'vmif3p0', 'vmif3s0', 'vmii1p0', 'vmii1s0', 'vmii2p0', 'vmii2s0', 'vmii3p0', 'vmii3s0', 'vmip1p0', 'vmip1s0', 'vmip2p0', 'vmip2s0', 'vmip3p0', 'vmip3s0', 'vmis1p0', 'vmis1s0', 'vmis2s0', 'vmis3p0', 'vmis3s0', 'vmm01p0', 'vmm02s0', 'vmm03p0', 'vmm03s0', 'vmn0000', 'vmp00pf', 'vmp00pm', 'vmp00sf', 'vmp00sm', 'vmsi1p0', 'vmsi1s0', 'vmsi3p0', 'vmsi3s0', 'vmsp1p0', 'vmsp1s0', 'vmsp2p0', 'vmsp2s0', 'vmsp3p0', 'vmsp3s0', 'vsg0000', 'vsic1s0', 'vsic2s0', 'vsic3p0', 'vsic3s0', 'vsif1s0', 'vsif3p0', 'vsif3s0', 'vsii1p0', 'vsii1s0', 'vsii3p0', 'vsii3s0', 'vsip1p0', 'vsip1s0', 'vsip2s0', 'vsip3p0', 'vsip3s0', 'vsis1s0', 'vsis3p0', 'vsis3s0', 'vsm03s0', 'vsn0000', 'vsp00sm', 'vssf3s0', 'vssi3p0', 'vssi3s0', 'vssp1s0', 'vssp2s0', 'vssp3p0', 'vssp3s0']\n"
     ]
    }
   ],
   "source": [
    "# Print sorted tagset\n",
    "print(sorted(tagset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we cannot know what is each tag. However, we can see that some tags are similar. For that, we will show some examples for each tag begining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dedicada', 'aq0fsp'),\n",
       " ('democrático', 'aq0ms0'),\n",
       " ('político', 'aq0ms0'),\n",
       " ('fundamentales', 'aq0cp0'),\n",
       " ('eficiente', 'aq0cs0'),\n",
       " ('participativa', 'aq0fs0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('a') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('la', 'da0fs0'),\n",
       " ('la', 'da0fs0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('los', 'da0mp0'),\n",
       " ('las', 'da0fp0'),\n",
       " ('la', 'da0fs0'),\n",
       " ('una', 'di0fs0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('d') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('La_Declaración_de_Viña_del_Mar', 'np0000a'),\n",
       " ('Gobernabilidad', 'ncfs000'),\n",
       " ('democracia', 'ncfs000'),\n",
       " ('compromiso', 'ncms000'),\n",
       " ('sistema', 'ncms000'),\n",
       " ('Estado_de_Derecho', 'np0000a'),\n",
       " ('pluralismo', 'ncms000'),\n",
       " ('derechos_humanos', 'ncmp000'),\n",
       " ('libertades', 'ncfp000'),\n",
       " ('marco', 'ncms000'),\n",
       " ('gobernabilidad', 'ncfs000'),\n",
       " ('democracia', 'ncfs000')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('n') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 'pr0cn000'), ('se', 'p0300000'), ('que', 'pr0cn000')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[300] if tag.startswith('p') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to use our POS tagger with a example for seeing how it tags that example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('me', 'pp1cs000'),\n",
       " ('pones', 'vmip3s0'),\n",
       " ('una', 'di0fs0'),\n",
       " ('pizza', 'ncfs000'),\n",
       " ('de', 'sps00'),\n",
       " ('cuatro', 'dn0cp0'),\n",
       " ('quesos', 'ncmp000'),\n",
       " ('?', 'Fit'),\n",
       " (',', 'Fc'),\n",
       " ('un', 'di0ms0'),\n",
       " ('buen', 'aq0ms0'),\n",
       " ('bocata', 'ncms000'),\n",
       " ('con', 'sps00'),\n",
       " ('pepinillos', 'np0000l'),\n",
       " ('y', 'cc'),\n",
       " ('chorizo', 'sn.e-SUJ')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'me pones una pizza de cuatro quesos?, un buen bocata con pepinillos y chorizo'\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can know what is the meaning of some tags:\n",
    "    \n",
    "    \n",
    "| Tag Begining | Meaning |\n",
    "|--------------|---------|\n",
    "|       a      | adjetive|\n",
    "| d | determiner |\n",
    "| n | noun |\n",
    "\n",
    "That is useful for create our `RegexParser`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: `RegexParser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we are going to define the grammar for `RegexpParser` and with that, we can create the `RegexpParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grammar\n",
    "grammar = r\"\"\"\n",
    "    Comida: {<s?n[cp\\.].*><s.*>?<s?[na][cp\\.].*>*}\n",
    "            {<s?n[cp\\.].*>}\n",
    "    Cantidad: {<d[in].*>}\n",
    "              {<Z.*>}  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create the RegexParser\n",
    "regex_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's use our parser with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  yo/pp1csn00\n",
      "  quiero/vmip1s0\n",
      "  (Cantidad 3/di0fp0)\n",
      "  (Comida bocadillos/ncfp000 con/sps00 pimiento/np0000l)\n",
      "  ,/Fc\n",
      "  (Cantidad 3/Z)\n",
      "  (Comida pizzas/ncmp000)\n",
      "  y/cc\n",
      "  (Comida ensalada/sn.e-SUJ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yo', 'pp1csn00', 'O'),\n",
       " ('quiero', 'vmip1s0', 'O'),\n",
       " ('3', 'di0fp0', 'B-Cantidad'),\n",
       " ('bocadillos', 'ncfp000', 'B-Comida'),\n",
       " ('con', 'sps00', 'I-Comida'),\n",
       " ('pimiento', 'np0000l', 'I-Comida'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('3', 'Z', 'B-Cantidad'),\n",
       " ('pizzas', 'ncmp000', 'B-Comida'),\n",
       " ('y', 'cc', 'O'),\n",
       " ('ensalada', 'sn.e-SUJ', 'B-Comida')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the example sentence\n",
    "sentence = 'yo quiero 3 bocadillos con pimiento, 3 pizzas y ensalada'\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Tag the sentence\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "\n",
    "# Chunk the tagged sentence\n",
    "chunked = regex_parser.parse(tagged)\n",
    "print(chunked)\n",
    "nltk.chunk.tree2conlltags(chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the statement of that practical case ask us what food is deliveried and its amount. So, let's make a function which is able to give it from a chunked sentence. It is important to know that with that function, we assume the following structures in a sentence:\n",
    "\n",
    "1. [...] Cantidad Comida [...]\n",
    "2. [...] Comida [...]\n",
    "\n",
    "In 2 case, we assume that `Cantidad = 1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, the statement of that practical case ask us what food is deliveried and its amount. \n",
    "# That function is able to give it from a chunked sentence. \n",
    "\n",
    "# It is important to know that with that function, we assume the following structures in a sentence:\n",
    "\n",
    "    # 1. [...] Cantidad Comida [...]\n",
    "    # 2. [...] Comida [...]\n",
    "\n",
    "# In 2 case, we assume that `Cantidad = 1`. \n",
    "def getFoodOrders(chunked_sentence) :\n",
    "    delivery = []\n",
    "    dic = {}\n",
    "    default_cantidad = 1\n",
    "\n",
    "    chunks = [ chunk for chunk in nltk.chunk.tree2conlltags(chunked_sentence) \n",
    "                  if 'Cantidad' in chunk[2] or 'Comida' in chunk[2] ]\n",
    "    \n",
    "    i = 0\n",
    "    while (i < len(chunks)):\n",
    "        chunk = chunks[i]\n",
    "        w, t, c = chunk\n",
    "        \n",
    "        if c == 'B-Cantidad' :\n",
    "            dic['cantidad'] = w\n",
    "\n",
    "        if c == 'B-Comida' :\n",
    "            if 'cantidad' not in dic :\n",
    "                dic['cantidad'] = default_cantidad\n",
    "\n",
    "            dic['comida'] = w\n",
    "            \n",
    "            j = i+1\n",
    "                  \n",
    "            condition = (j < len(chunks))\n",
    "            while (condition) :\n",
    "                w, t, c = chunks[j]\n",
    "                \n",
    "                if c == 'I-Comida' :\n",
    "                    if 'ingredientes' not in dic :\n",
    "                        dic['ingredientes'] = w\n",
    "                    else :\n",
    "                        dic['ingredientes'] = dic['ingredientes'] + \" \" + w\n",
    "        \n",
    "                j += 1\n",
    "                condition = (j < len(chunks) and c == 'I-Comida')\n",
    "   \n",
    "            delivery.append(dic)\n",
    "            dic = {}\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    return delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo quiero 3 bocadillos con pimiento, 3 pizzas y ensalada\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cantidad': '3', 'comida': 'bocadillos', 'ingredientes': 'con pimiento'},\n",
       " {'cantidad': '3', 'comida': 'pizzas'},\n",
       " {'cantidad': 1, 'comida': 'ensalada'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the food orders of our example\n",
    "print(sentence)\n",
    "getFoodOrders(chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: `UnigramChunker` and `BigramChunker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For make that version, we have to consider that for using the `UnigramChunker`, `BigramChunker` and `NaiveBayesClassifier`, we need a corpus which will be used by training them. That corpus has to be in IOB format, and we are going to use our `RegexpParser` with a sentences corpus for making our training corpus.\n",
    "\n",
    "So, let's create our sentences corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus with sentences\n",
    "corpus = [\n",
    "    \"Me gustaría comer una tortilla de patatas\",\n",
    "    \"¿Nos pones 3 tocinos, 4 pechugas?\",\n",
    "    \"5 repollos, 12 sardinas y 8 jalapeños\",\n",
    "    \"Estamos indecisos, pero puedes ponernos mientras tres raciones de patatas fritas\",\n",
    "    \"¿Sería tan amable de servirnos catorce tostadas?\",\n",
    "    \"Queremos 2 pollos con caracoles, una ternera, tres patos y 2 pimientos con arroz\",\n",
    "    \"Nuestro pedido es: 10 hamburguesas con queso, 20 pizzas y 3 patatas\",\n",
    "    \"Yo quiero 9 yogures, 12 ensaladas, un pimiento, 4 chorizos, 12 empanadillas de atún, 8 crespillos y 3 alubias\",\n",
    "    \"Me gustaría comer: kiwi con ensalada\",\n",
    "    \"Él quiere pedir 3 tostadas, 2 tomates y 6 uvas\",\n",
    "    \"Ellos han pedido 2 higos, 1 salmón con caracoles y arroz\",\n",
    "    \"Tú has pedido 4 fajitas de pollo, dos emperadores con patatas y tres rúculas\",\n",
    "    \"2 macarrones, 3 quesos, una guindilla, cuatro pulpos y quince verduras\",\n",
    "    \"Mi abuela quiere emperador con ensalada\",\n",
    "    \"Mi tía quiere comer marisco y carne\",\n",
    "    \"2 cebollas, una calabaza y ocho tomates\",\n",
    "    \"tres pollos, dos corderos, cuatro cerdos y tres macarrones\",\n",
    "    \"Pepinillos, calabaza, navajas, sepia y gulas\",\n",
    "    \"Me gustaría comer bonito a la plancha con patatas asadas\",\n",
    "    \"Pídete cinco pomelos, tres calabacines, 8 mangos, seis melocotones\"\n",
    "    \"Langosta, langostinos y almejas\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our `RegexpParser` together with our Spanish POS tagger for create a IOB corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIOBCorpus(corpus, pos_tagger, regex_parser) :\n",
    "\n",
    "    iob_corpus = []\n",
    "\n",
    "    # For each sentence in corpus\n",
    "    for sent in corpus :\n",
    "        # Tokenize the sentence\n",
    "        tokens = nltk.word_tokenize(sent)\n",
    "\n",
    "        # Tag the sentence\n",
    "        tagged_sent = pos_tagger.tag(tokens)\n",
    "\n",
    "        # Parse tagged_sent\n",
    "        chunked_sent = regex_parser.parse(tagged_sent)\n",
    "\n",
    "        iob_corpus.append(chunked_sent)\n",
    "    \n",
    "    return iob_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iob_corpus = createIOBCorpus(corpus, spanish_pos_tagger, regex_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes's definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's define `UnigramChunker` and `BigramChunker` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.UnigramTagger(train_data) \n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data) \n",
    "\n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to split the `iob_corpus` between training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = iob_corpus[0:14]\n",
    "testing = iob_corpus[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(iob_corpus) = 20\n",
      "len(training) = 14\n",
      "len(testing) = 6\n"
     ]
    }
   ],
   "source": [
    "print('len(iob_corpus) =', len(iob_corpus))\n",
    "print('len(training) =', len(training))\n",
    "print('len(testing) =', len(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the `UnigramChunker` and test its parse with a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  96.7%%\n",
      "    Precision:     90.6%%\n",
      "    Recall:        96.7%%\n",
      "    F-Measure:     93.5%%\n",
      "\n",
      "¿Sería tan amable de servirnos catorce tostadas?\n",
      "[{'cantidad': 1, 'comida': '¿Sería'}, {'cantidad': 1, 'comida': 'de'}, {'cantidad': 'catorce', 'comida': 'tostadas'}]\n"
     ]
    }
   ],
   "source": [
    "unigram_chunker = UnigramChunker(training)\n",
    "print(unigram_chunker.evaluate(testing))\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus[4])\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "\n",
    "print()\n",
    "print(corpus[4])\n",
    "print(getFoodOrders(unigram_chunker.parse(tagged)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try `BigramChunker`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  82.0%%\n",
      "    Precision:    100.0%%\n",
      "    Recall:        70.0%%\n",
      "    F-Measure:     82.4%%\n",
      "\n",
      "Queremos 2 pollos con caracoles, una ternera, tres patos y 2 pimientos con arroz\n",
      "[{'cantidad': '2', 'comida': 'pollos', 'ingredientes': 'con caracoles'}, {'cantidad': 'una', 'comida': 'ternera'}, {'cantidad': 'tres', 'comida': 'patos'}, {'cantidad': '2', 'comida': 'pimientos', 'ingredientes': 'con arroz'}]\n"
     ]
    }
   ],
   "source": [
    "bigram_chunker = BigramChunker(training)\n",
    "print(bigram_chunker.evaluate(testing))\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus[5])\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "\n",
    "print()\n",
    "print(corpus[5])\n",
    "print(getFoodOrders(bigram_chunker.parse(tagged)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3: `NaiveBayesChunker` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the `NaiveBayesChunker` class using the `ConsecutivePosTagger` class for tagging the sentences using `NaiveBayesClassifier` classifier. \n",
    "\n",
    "Also, we define the features extractor fuction: `pos_features`. Now, this function only returns the part-of-speech tag of the current token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history) \n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "                \n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)\n",
    "\n",
    "    \n",
    "    \n",
    "class NaiveBayesChunker(nltk.ChunkParserI): \n",
    "    def __init__(self, train_sents):\n",
    "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
    "                         nltk.chunk.tree2conlltags(sent)]\n",
    "                        for sent in train_sents]\n",
    "        self.tagger = ConsecutivePosTagger(tagged_sents)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        tagged_sents = self.tagger.tag(sentence)\n",
    "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    return {\"pos\": pos}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the `NaiveBayesChunker` and test its parse with a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  96.7%%\n",
      "    Precision:     90.6%%\n",
      "    Recall:        96.7%%\n",
      "    F-Measure:     93.5%%\n",
      "\n",
      "Yo quiero 9 yogures, 12 ensaladas, un pimiento, 4 chorizos, 12 empanadillas de atún, 8 crespillos y 3 alubias\n",
      "\n",
      "[{'cantidad': 1, 'comida': 'yogures'}, {'cantidad': '12', 'comida': 'ensaladas'}, {'cantidad': 'un', 'comida': 'pimiento'}, {'cantidad': '12', 'comida': 'empanadillas', 'ingredientes': 'de atún'}, {'cantidad': '8', 'comida': 'crespillos'}, {'cantidad': '3', 'comida': 'alubias'}]\n"
     ]
    }
   ],
   "source": [
    "naive_chunker = NaiveBayesChunker(training)\n",
    "print(naive_chunker.evaluate(testing))\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus[7])\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "\n",
    "parsed = naive_chunker.parse(tagged)\n",
    "\n",
    "print()\n",
    "print(corpus[7])\n",
    "print()\n",
    "print(getFoodOrders(parsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to update the `pos_features` function to using the previous POS tag in the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " def pos_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "    \n",
    "    return {\"pos\": pos, \"prevpos\": prevpos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  90.2%%\n",
      "    Precision:     81.2%%\n",
      "    Recall:        86.7%%\n",
      "    F-Measure:     83.9%%\n",
      "\n",
      "Queremos 2 pollos con caracoles, una ternera, tres patos y 2 pimientos con arroz\n",
      "\n",
      "[{'cantidad': '2', 'comida': 'pollos', 'ingredientes': 'con caracoles'}, {'cantidad': 'una', 'comida': 'ternera'}, {'cantidad': 'tres', 'comida': 'patos'}, {'cantidad': '2', 'comida': 'pimientos', 'ingredientes': 'con arroz'}]\n"
     ]
    }
   ],
   "source": [
    "naive_chunker = NaiveBayesChunker(training)\n",
    "print(naive_chunker.evaluate(testing))\n",
    "\n",
    "tokens = nltk.word_tokenize(corpus[5])\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "\n",
    "parsed = naive_chunker.parse(tagged)\n",
    "\n",
    "print()\n",
    "print(corpus[5])\n",
    "print()\n",
    "print(getFoodOrders(parsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have the models which the statemente requires, then we are going to make an evaluation of the models to know what is better in this practical case. This evaluation will be made using our `iob_corpus` with 20 sentences, 14 of them used by training and the other 6 used by testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(iob_corpus) = 20\n",
      "len(training) = 14\n",
      "len(testing) = 6\n"
     ]
    }
   ],
   "source": [
    "# Create a corpus with sentences\n",
    "corpus = [\n",
    "    \"Me gustaría comer una tortilla de patatas\",\n",
    "    \"¿Nos pones 3 tocinos, 4 pechugas?\",\n",
    "    \"5 repollos, 12 sardinas y 8 jalapeños\",\n",
    "    \"Estamos indecisos, pero puedes ponernos mientras tres raciones de patatas fritas\",\n",
    "    \"¿Sería tan amable de servirnos catorce tostadas?\",\n",
    "    \"Queremos 2 pollos con caracoles, una ternera, tres patos y 2 pimientos con arroz\",\n",
    "    \"Nuestro pedido es: 10 hamburguesas con queso, 20 pizzas y 3 patatas\",\n",
    "    \"Yo quiero 9 yogures, 12 ensaladas, un pimiento, 4 chorizos, 12 empanadillas de atún, 8 crespillos y 3 alubias\",\n",
    "    \"Me gustaría comer: kiwi con ensalada\",\n",
    "    \"Él quiere pedir 3 tostadas, 2 tomates y 6 uvas\",\n",
    "    \"Ellos han pedido 2 higos, 1 salmón con caracoles y arroz\",\n",
    "    \"Tú has pedido 4 fajitas de pollo, dos emperadores con patatas y tres rúculas\",\n",
    "    \"2 macarrones, 3 quesos, una guindilla, cuatro pulpos y quince verduras\",\n",
    "    \"Mi abuela quiere emperador con ensalada\",\n",
    "    \"Mi tía quiere comer marisco y carne\",\n",
    "    \"2 cebollas, una calabaza y ocho tomates\",\n",
    "    \"tres pollos, dos corderos, cuatro cerdos y tres macarrones\",\n",
    "    \"Pepinillos, calabaza, navajas, sepia y gulas\",\n",
    "    \"Me gustaría comer bonito a la plancha con patatas asadas\",\n",
    "    \"Pídete cinco pomelos, tres calabacines, 8 mangos, seis melocotones\"\n",
    "    \"Langosta, langostinos y almejas\"\n",
    "]\n",
    "\n",
    "# Function which create IOB corpus using a pos_tagger and regex_parser params\n",
    "def createIOBCorpus(corpus, pos_tagger, regex_parser) :\n",
    "\n",
    "    iob_corpus = []\n",
    "\n",
    "    # For each sentence in corpus\n",
    "    for sent in corpus :\n",
    "        # Tokenize the sentence\n",
    "        tokens = nltk.word_tokenize(sent)\n",
    "\n",
    "        # Tag the sentence\n",
    "        tagged_sent = pos_tagger.tag(tokens)\n",
    "\n",
    "        # Parse tagged_sent\n",
    "        chunked_sent = regex_parser.parse(tagged_sent)\n",
    "\n",
    "        iob_corpus.append(chunked_sent)\n",
    "    \n",
    "    return iob_corpus\n",
    "\n",
    "# Create the IOB corpus using our corpus\n",
    "iob_corpus = createIOBCorpus(corpus, spanish_pos_tagger, regex_parser)\n",
    "\n",
    "# Split the IOB corpus between training and testing sets\n",
    "training = iob_corpus[0:14]\n",
    "testing = iob_corpus[14:]\n",
    "\n",
    "print('len(iob_corpus) =', len(iob_corpus))\n",
    "print('len(training) =', len(training))\n",
    "print('len(testing) =', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramChunker evaluation\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  96.7%%\n",
      "    Precision:     90.6%%\n",
      "    Recall:        96.7%%\n",
      "    F-Measure:     93.5%%\n"
     ]
    }
   ],
   "source": [
    "print(\"UnigramChunker evaluation\")\n",
    "print(unigram_chunker.evaluate(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramChunker evaluation\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  82.0%%\n",
      "    Precision:    100.0%%\n",
      "    Recall:        70.0%%\n",
      "    F-Measure:     82.4%%\n"
     ]
    }
   ],
   "source": [
    "print(\"BigramChunker evaluation\")\n",
    "print(bigram_chunker.evaluate(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesChunker evaluation - Only current POS tag\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  96.7%%\n",
      "    Precision:     90.6%%\n",
      "    Recall:        96.7%%\n",
      "    F-Measure:     93.5%%\n"
     ]
    }
   ],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "        \n",
    "    return {\"pos\": pos}\n",
    "\n",
    "\n",
    "naive_chunker = NaiveBayesChunker(training)\n",
    "print(\"NaiveBayesChunker evaluation - Only current POS tag\")\n",
    "print(naive_chunker.evaluate(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayesChunker evaluation - Current POS tag and previous POS tag\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  90.2%%\n",
      "    Precision:     81.2%%\n",
      "    Recall:        86.7%%\n",
      "    F-Measure:     83.9%%\n"
     ]
    }
   ],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "        \n",
    "    return {\"pos\": pos, \"prevpos\": prevpos}\n",
    "\n",
    "\n",
    "naive_chunker = NaiveBayesChunker(training)\n",
    "print(\"NaiveBayesChunker evaluation - Current POS tag and previous POS tag\")\n",
    "print(naive_chunker.evaluate(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, all results are high due to the corpus is small and with a small variety. That causes the models have a little overfitting. Also, we can observe that the best models are `UnigramChunker` and `NaiveBayesChunker` (with current POS tag only). This is because in that practical case, the word context is not essential to tag it. For that, `BigramChunker` and `NaiveBayesChunker` (with previous POS tag) have a smaller evaluation, these models using the word context to tag it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusions of that practical case are:\n",
    "\n",
    "- A training corpus which is big and has variety is very important, because it is used by the models to training and if it is small and has a little variety the models will be overfitted and its training is not good.\n",
    "- Theoretically, using `NaiveBayesClassifier` the results should be better, because with it, we can train the model with more sentence data, like it can be the word context. However, in that practical case, the word context is not essential to word's tagging.\n",
    "- In summary, for that practical case, the best model is `UnigramChunker`, because it has simplier than `NaiveBayesChunker` and it has a the same results.\n",
    "\n",
    "With that conclusions, in [01-food-orders](./01-food-orders) notebook provides the function required by the statement with all models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
