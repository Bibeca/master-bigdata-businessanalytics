{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical case - Food Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statement (written in spanish) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio se va a imaginar que se trabaja para una empresa de envíos de comida, presente\n",
    "en todo el territorio nacional, con miles de pedidos cada día. Dicha empresa tiene un fichero histórico\n",
    "con todas las peticiones de comida que los clientes han realizado mediante el chat de su web en los\n",
    "últimos meses. Necesitan analizar en tiempo real qué comidas están pidiendo los usuarios y qué\n",
    "ingredientes tenían, ya que en la cadena de stock de alimentos es necesario realizar una previsión para\n",
    "no quedarse sin platos cocinados. \n",
    "\n",
    "Se ha calculado que el impacto en las ventas cada vez que uno de\n",
    "los platos deja de estar disponible es del 7% de pérdidas en esa semana, debido al abandono de la web\n",
    "de pedidos por parte del cliente. Por tanto, es de vital importancia poder realizar automáticamente\n",
    "estimaciones al respecto.\n",
    "\n",
    "El objetivo es programar una función que reciba como input un texto de usuario y devuelva los\n",
    "fragmentos de texto (chunks) que hagan referencia a las comidas y cantidades que ha solicitado. No es\n",
    "necesario, ni es el objetivo de este ejercicio, construir un clasificador de intención previo a esta\n",
    "función, sino simplemente una función que presuponemos recibe una frase con la intención\n",
    "`Pedir_comida`. Tampoco es objetivo normalizar la salida (por ej.: no es necesario convertir 'tres' a '3'\n",
    "ni 'pizzas' a 'pizza'). Es, por tanto, un ejercicio de mínimos.\n",
    "\n",
    "    Por ejemplo: “quiero 3 bocadillos de anchoas y 2 pizzas” →\n",
    "    [\n",
    "        {comida:'bocadillo', ingrediente:'anchoas', cantidad:3},\n",
    "        {comida:'pizza', ingrediente:'null', cantidad:2}\n",
    "    ]\n",
    "    \n",
    "Por tanto, la salida de la función será un array con diccionarios de 2 elementos (`comida` y `cantidad`).\n",
    "Cuando una cantidad no sea detectada, se pondrá su valor a '1' como valor por defecto.\n",
    "\n",
    "Este ejercicio hay que hacerlo con textos de entrenamiento en español, pero teniendo en cuenta que\n",
    "la precisión de los POS taggers en castellano de NLTK es muy mala. Por tanto, el alumno no debe\n",
    "frustrarse por no obtener buenos resultados, como hemos dicho anteriormente se trata simplemente de\n",
    "un ejercicio teórico y podemos suponer que, con un mejor analizador, podríamos obtener mejores\n",
    "resultados.\n",
    "\n",
    "Para llevar a cabo la práctica, deberá construirse una cadena NLP con NLTK, con los siguientes\n",
    "elementos:\n",
    "    - segmentación de frases,\n",
    "    - tokenización,\n",
    "    - POS tagger (analizador mofológico para el español).\n",
    "\n",
    "A continuación, los POS tags obtenidos serán usados por el `RegexParser`, el `UnigramParser`, el\n",
    "`BigramParser` y el `NaiveBayesClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import NLTK and Spanish CESS Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "# Load all tagged sentences of Spanish CESS corpus\n",
    "sents = cess_esp.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagger training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making the several versions required by that practical case, we have to train a POS tagger for Spanish CESS corpus. For that, we are going to use the `HiddenMarkovModelTagger` tagger, because that tagger is more complete than `UnigramTagger`, `BigramTagger` and `TrigramTagger` taggers.\n",
    "\n",
    "At first, we will make the train (90%) and test (10%) datasets and evaluate if the trained model is not overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "\n",
    "for i in range(len(sents)) :\n",
    "    if i % 10 :\n",
    "        training.append(sents[i])\n",
    "    else :\n",
    "        testing.append(sents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sents) = 6030\n",
      "len(training) = 5427\n",
      "len(testing) = 603\n"
     ]
    }
   ],
   "source": [
    "print('len(sents) =', len(sents))\n",
    "print('len(training) =', len(training))\n",
    "print('len(testing) =', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 89.88905831011094\n"
     ]
    }
   ],
   "source": [
    "# Import HiddenMarkovModelTagger\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "# Create the Spanish POS tagger using HMM Tagger\n",
    "spanish_pos_tagger = HiddenMarkovModelTagger.train(training)\n",
    "\n",
    "# Evaluate that tagger\n",
    "print('Evaluation:', spanish_pos_tagger.evaluate(testing)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, that model is not overfitting and its evaluation is good. So, we will use that POS tagger for our tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Part-of-Speech Tagset of Spanish CESS Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using `RegexParser`, we have to know how are the Spanish tags provided by our tagger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set which will contain all tags\n",
    "tagset = set()\n",
    "\n",
    "for sent in sents :\n",
    "    tagset.update([ tag for (word, tag) in sent ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Faa', 'Fat', 'Fc', 'Fd', 'Fe', 'Fg', 'Fh', 'Fia', 'Fit', 'Fp', 'Fpa', 'Fpt', 'Fs', 'Fx', 'Fz', 'I', 'W', 'X', 'Y', 'Z', 'Zm', 'Zp', 'ao0fp0', 'ao0fs0', 'ao0mp0', 'ao0ms0', 'aq00000', 'aq0cn0', 'aq0cp0', 'aq0cs0', 'aq0fp0', 'aq0fpp', 'aq0fs0', 'aq0fsp', 'aq0mp0', 'aq0mpp', 'aq0ms0', 'aq0msp', 'cc', 'cs', 'da0fp0', 'da0fs0', 'da0mp0', 'da0ms0', 'da0ns0', 'dd0cp0', 'dd0cs0', 'dd0fp0', 'dd0fs0', 'dd0mp0', 'dd0ms0', 'de0cn0', 'di0cp0', 'di0cs0', 'di0fp0', 'di0fs0', 'di0mp0', 'di0ms0', 'dn0cp0', 'dn0cs0', 'dn0fp0', 'dn0fs0', 'dn0mp0', 'dn0ms0', 'dp1cps', 'dp1css', 'dp1fpp', 'dp1fsp', 'dp1mpp', 'dp1msp', 'dp1mss', 'dp2cps', 'dp2css', 'dp3cp0', 'dp3cs0', 'dp3fs0', 'dp3mp0', 'dp3ms0', 'dt0cn0', 'dt0fs0', 'dt0ms0', 'i', 'nc00000', 'nccn000', 'nccp000', 'nccs000', 'ncfn000', 'ncfp000', 'ncfs000', 'ncmn000', 'ncmp000', 'ncms000', 'np00000', 'np0000a', 'np0000l', 'np0000o', 'np0000p', 'p0000000', 'p010p000', 'p010s000', 'p020s000', 'p0300000', 'pd0cp000', 'pd0cs000', 'pd0fp000', 'pd0fs000', 'pd0mp000', 'pd0ms000', 'pd0ns000', 'pe000000', 'pi0cp000', 'pi0cs000', 'pi0fp000', 'pi0fs000', 'pi0mp000', 'pi0ms000', 'pn0cp000', 'pn0fp000', 'pn0fs000', 'pn0mp000', 'pn0ms000', 'pp1cp000', 'pp1cs000', 'pp1csn00', 'pp1cso00', 'pp1mp000', 'pp2cp000', 'pp2cp00p', 'pp2cs000', 'pp2cs00p', 'pp2csn00', 'pp2cso00', 'pp3cn000', 'pp3cna00', 'pp3cno00', 'pp3cpa00', 'pp3cpd00', 'pp3csa00', 'pp3csd00', 'pp3fp000', 'pp3fpa00', 'pp3fs000', 'pp3fsa00', 'pp3mp000', 'pp3mpa00', 'pp3ms000', 'pp3msa00', 'pp3ns000', 'pr000000', 'pr0cn000', 'pr0cp000', 'pr0cs000', 'pr0fp000', 'pr0fs000', 'pr0mp000', 'pr0ms000', 'pt000000', 'pt0cp000', 'pt0cs000', 'pt0mp000', 'pt0ms000', 'px1fp0p0', 'px1fs0p0', 'px1mp0p0', 'px1ms0p0', 'px2fs0s0', 'px3fs000', 'px3mp000', 'px3ms000', 'px3ns000', 'rg', 'rn', 'sn-SUJ', 'sn.co-SUJ', 'sn.e', 'sn.e-ATR', 'sn.e-CD', 'sn.e-SUJ', 'sn.e.1n-SUJ', 'spcms', 'sps00', 'vag0000', 'vaic1p0', 'vaic3p0', 'vaic3s0', 'vaif1p0', 'vaif2s0', 'vaif3p0', 'vaif3s0', 'vaii1p0', 'vaii1s0', 'vaii2s0', 'vaii3p0', 'vaii3s0', 'vaip1p0', 'vaip1s0', 'vaip2p0', 'vaip2s0', 'vaip3p0', 'vaip3s0', 'vais3s0', 'vam02s0', 'vam03s0', 'van0000', 'vap00sm', 'vasi1p0', 'vasi1s0', 'vasi3p0', 'vasi3s0', 'vasp1s0', 'vasp3p0', 'vasp3s0', 'vmg0000', 'vmic1p0', 'vmic1s0', 'vmic2s0', 'vmic3p0', 'vmic3s0', 'vmif1p0', 'vmif1s0', 'vmif2s0', 'vmif3p0', 'vmif3s0', 'vmii1p0', 'vmii1s0', 'vmii2p0', 'vmii2s0', 'vmii3p0', 'vmii3s0', 'vmip1p0', 'vmip1s0', 'vmip2p0', 'vmip2s0', 'vmip3p0', 'vmip3s0', 'vmis1p0', 'vmis1s0', 'vmis2s0', 'vmis3p0', 'vmis3s0', 'vmm01p0', 'vmm02s0', 'vmm03p0', 'vmm03s0', 'vmn0000', 'vmp00pf', 'vmp00pm', 'vmp00sf', 'vmp00sm', 'vmsi1p0', 'vmsi1s0', 'vmsi3p0', 'vmsi3s0', 'vmsp1p0', 'vmsp1s0', 'vmsp2p0', 'vmsp2s0', 'vmsp3p0', 'vmsp3s0', 'vsg0000', 'vsic1s0', 'vsic2s0', 'vsic3p0', 'vsic3s0', 'vsif1s0', 'vsif3p0', 'vsif3s0', 'vsii1p0', 'vsii1s0', 'vsii3p0', 'vsii3s0', 'vsip1p0', 'vsip1s0', 'vsip2s0', 'vsip3p0', 'vsip3s0', 'vsis1s0', 'vsis3p0', 'vsis3s0', 'vsm03s0', 'vsn0000', 'vsp00sm', 'vssf3s0', 'vssi3p0', 'vssi3s0', 'vssp1s0', 'vssp2s0', 'vssp3p0', 'vssp3s0']\n"
     ]
    }
   ],
   "source": [
    "# Print sorted tagset\n",
    "print(sorted(tagset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we cannot know what is each tag. However, we can see that some tags are similar. For that, we will show some examples for each tag begining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dedicada', 'aq0fsp'),\n",
       " ('democrático', 'aq0ms0'),\n",
       " ('político', 'aq0ms0'),\n",
       " ('fundamentales', 'aq0cp0'),\n",
       " ('eficiente', 'aq0cs0'),\n",
       " ('participativa', 'aq0fs0')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('a') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('la', 'da0fs0'),\n",
       " ('la', 'da0fs0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('el', 'da0ms0'),\n",
       " ('los', 'da0mp0'),\n",
       " ('las', 'da0fp0'),\n",
       " ('la', 'da0fs0'),\n",
       " ('una', 'di0fs0')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('d') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('La_Declaración_de_Viña_del_Mar', 'np0000a'),\n",
       " ('Gobernabilidad', 'ncfs000'),\n",
       " ('democracia', 'ncfs000'),\n",
       " ('compromiso', 'ncms000'),\n",
       " ('sistema', 'ncms000'),\n",
       " ('Estado_de_Derecho', 'np0000a'),\n",
       " ('pluralismo', 'ncms000'),\n",
       " ('derechos_humanos', 'ncmp000'),\n",
       " ('libertades', 'ncfp000'),\n",
       " ('marco', 'ncms000'),\n",
       " ('gobernabilidad', 'ncfs000'),\n",
       " ('democracia', 'ncfs000')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[100] if tag.startswith('n') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 'pr0cn000'), ('se', 'p0300000'), ('que', 'pr0cn000')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (word, tag) for (word, tag) in sents[300] if tag.startswith('p') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to use our POS tagger with a example for seeing how it tags that example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('me', 'pp1cs000'),\n",
       " ('pones', 'vmip3s0'),\n",
       " ('una', 'di0fs0'),\n",
       " ('pizza', 'ncfs000'),\n",
       " ('de', 'sps00'),\n",
       " ('cuatro', 'dn0cp0'),\n",
       " ('quesos', 'ncmp000'),\n",
       " ('?', 'Fit'),\n",
       " (',', 'Fc'),\n",
       " ('un', 'di0ms0'),\n",
       " ('buen', 'aq0ms0'),\n",
       " ('bocata', 'ncms000'),\n",
       " ('con', 'sps00'),\n",
       " ('pepinillos', 'np0000l'),\n",
       " ('y', 'cc'),\n",
       " ('chorizo', 'sn.e-SUJ')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'me pones una pizza de cuatro quesos?, un buen bocata con pepinillos y chorizo'\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we can know what is the meaning of some tags:\n",
    "    \n",
    "    \n",
    "| Tag Begining | Meaning |\n",
    "|--------------|---------|\n",
    "|       a      | adjetive|\n",
    "| d | determiner |\n",
    "| n | noun |\n",
    "\n",
    "That is useful for create our `RegexParser`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: `RegexParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  yo/pp1csn00\n",
      "  quiero/vmip1s0\n",
      "  (Cantidad 3/di0fp0)\n",
      "  (Comida bocadillos/ncfp000)\n",
      "  con/sps00\n",
      "  (Comida pimiento/np0000l)\n",
      "  ,/Fc\n",
      "  (Cantidad 3/Z)\n",
      "  (Comida pizzas/ncmp000)\n",
      "  y/cc\n",
      "  (Comida ensalada/sn.e-SUJ))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yo', 'pp1csn00', 'O'),\n",
       " ('quiero', 'vmip1s0', 'O'),\n",
       " ('3', 'di0fp0', 'B-Cantidad'),\n",
       " ('bocadillos', 'ncfp000', 'B-Comida'),\n",
       " ('con', 'sps00', 'O'),\n",
       " ('pimiento', 'np0000l', 'B-Comida'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('3', 'Z', 'B-Cantidad'),\n",
       " ('pizzas', 'ncmp000', 'B-Comida'),\n",
       " ('y', 'cc', 'O'),\n",
       " ('ensalada', 'sn.e-SUJ', 'B-Comida')]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'yo quiero 3 bocadillos con pimiento, 3 pizzas y ensalada'\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "tagged = spanish_pos_tagger.tag(tokens)\n",
    "tagged\n",
    "\n",
    "\n",
    "# Define the grammar\n",
    "grammar = r\"\"\"\n",
    "    Comida: {<s?n.*>}      \n",
    "    Cantidad: {<[Zd].*>}   \n",
    "\"\"\"\n",
    "\n",
    "#Ingrediente: {<s.*>+<Comida>}\n",
    "#Pedido: {<Cantidad>?<Comida><Ingrediente>?}\n",
    "\n",
    "# Create the RegexParser\n",
    "regex_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Chunk the tagged sentence\n",
    "chunked = regex_parser.parse(tagged)\n",
    "print(chunked)\n",
    "nltk.chunk.tree2conlltags(chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cantidad': 3, 'comida': 'bocadillos'},\n",
       " {'cantidad': 1, 'comida': 'pimiento'},\n",
       " {'cantidad': 3, 'comida': 'pizzas'},\n",
       " {'cantidad': 1, 'comida': 'ensalada'}]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delivery = []\n",
    "dic = {}\n",
    "default_cantidad = 1\n",
    "\n",
    "for chunk in [ chunk for chunk in nltk.chunk.tree2conlltags(chunked) if 'B' in chunk[2] ] :\n",
    "    w, t, c = chunk\n",
    "    \n",
    "    if 'cantidad' not in dic :\n",
    "        if c == 'B-Cantidad' :\n",
    "            dic['cantidad'] = int(w)\n",
    "        else :\n",
    "            dic['cantidad'] = default_cantidad\n",
    "    \n",
    "    if 'comida' not in dic and c == 'B-Comida' :\n",
    "        dic['comida'] = w\n",
    "        delivery.append(dic)\n",
    "        dic = {}\n",
    "    \n",
    "delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
