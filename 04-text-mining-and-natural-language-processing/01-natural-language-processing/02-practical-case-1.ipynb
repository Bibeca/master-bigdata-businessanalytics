{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Practical case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the NLP chain which we used in the [last notebook](01-first-steps-nltk.ipynb), we have to do:\n",
    "\n",
    "- A NLP chain with the following elements:\n",
    "\n",
    "    `Word tokenization -> Lemmatization -> Syntactic analysis`\n",
    "\n",
    "\n",
    "- A NLP chain with the following elements:\n",
    "\n",
    "    `Word tokenization -> Lemmatization -> POS tagger -> Syntactic analysis`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: `Word tokenization -> Lemmatization -> Syntactic analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all packages which we need \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Text: I didn't notice my animals were uglier than yours! I'm sorry...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a input text for our NLP chain\n",
    "text = \"I didn't notice my animals were uglier than yours! I'm sorry...\"\n",
    "print (\"1. Text:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Tokens: ['I', 'did', \"n't\", 'notice', 'my', 'animals', 'were', 'uglier', 'than', 'yours', '!', 'I', \"'m\", 'sorry', '...']\n"
     ]
    }
   ],
   "source": [
    "# 2. Tokenization: Tokenize the text, i.e: split the text on tokens\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print (\"2. Tokens:\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Morphology analysis: [('I', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('notice', 'VB'), ('my', 'PRP$'), ('animals', 'NNS'), ('were', 'VBD'), ('uglier', 'JJR'), ('than', 'IN'), ('yours', 'JJR'), ('!', '.'), ('I', 'PRP'), (\"'m\", 'VBP'), ('sorry', 'JJ'), ('...', ':')]\n"
     ]
    }
   ],
   "source": [
    "# 3. Morphology/Lexical analysis: set a morphology tag for each token\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print (\"3. Morphology analysis:\",tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Lemmas: \n",
      "['i', 'do', 'not', 'notice', 'my', 'animal', 'be', 'ugly', 'than', 'yours', '!', 'i', 'be', 'sorry', '...']\n"
     ]
    }
   ],
   "source": [
    "# Create the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# WordNetLemmatizer only knows 4 POS tags: a (adjetive), r (adverb), n (noun) and v (verb)\n",
    "# For that, we should convert Penn Tree Bank format to WordNet format \n",
    "# (e.g: N->n, J->a, R->r, V->V, ...)\n",
    "\n",
    "wnTags = {'N':wordnet.NOUN, 'J':wordnet.ADJ, 'V':wordnet.VERB, 'R':wordnet.ADV} \n",
    "\n",
    "# Create a lemmas array for storage the lemmas:\n",
    "lemmas = []\n",
    "\n",
    "print (\"4. Lemmas: \")\n",
    "# For each token and its tag:\n",
    "for (tok,tag) in tagged:\n",
    "    # WordNet has not the short forms: 'm, n't, so we should introduce them for the good lemmatization\n",
    "    if tok=='\\'m':\n",
    "        tok = 'am'\n",
    "    if tok=='\\'s':\n",
    "        tok = 'is'\n",
    "    if tok=='n\\'t':\n",
    "        tok = 'not'\n",
    "        \n",
    "    # We only get the first char of the tag because we use it to convert it to WordNet format\n",
    "    tag = tag[:1]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemma = lemmatizer.lemmatize(tok.lower(), wnTags.get(tag, wordnet.NOUN))\n",
    "\n",
    "    # Other alternative for get the lemma can be use the wordnet.morphy() function \n",
    "    #lemma = wordnet.morphy(tok.lower(), wnTags.get(tag, wordnet.NOUN))\n",
    "    \n",
    "    \n",
    "    if lemma is None: # If WordNet has not the word, we assign its token to the lemma\n",
    "       lemma = tok.lower() \n",
    "    lemmas.append(lemma)\n",
    "\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Syntactic analysis:\n",
      "\n",
      "|.i .do.no.no.my.an.be.ug.th.yo.! .i .be.so....|\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] 'i'\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] 'do'\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .  .  .| [2:3] 'not'\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] 'notice'\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .  .  .| [4:5] 'my'\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] 'animal'\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .  .  .| [6:7] 'be'\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .  .  .| [7:8] 'ugly'\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .  .  .| [8:9] 'than'\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .  .  .| [9:10] 'yours'\n",
      "|.  .  .  .  .  .  .  .  .  .  [--]  .  .  .  .| [10:11] '!'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] 'i'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]  .  .| [12:13] 'be'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  [--]  .| [13:14] 'sorry'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  .  [--]| [14:15] '...'\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] Noun -> 'i' *\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] NP -> Noun *\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] NP -> Noun * Verb Adj Punt\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] PP -> Noun * Det Noun VP\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] S  -> NP * VP\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] Verb -> 'do' *\n",
      "|.  [-->  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] VP -> Verb * Adv PP\n",
      "|.  [-->  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] VP -> Verb * Adj Conj Det Punt\n",
      "|[----->  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:2] NP -> Noun Verb * Adj Punt\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .  .  .| [2:3] Adv -> 'not' *\n",
      "|.  [----->  .  .  .  .  .  .  .  .  .  .  .  .| [1:3] VP -> Verb Adv * PP\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] Noun -> 'notice' *\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] NP -> Noun *\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] PP -> Noun * Det Noun VP\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] S  -> NP * VP\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .  .  .| [4:5] Det -> 'my' *\n",
      "|.  .  .  [----->  .  .  .  .  .  .  .  .  .  .| [3:5] PP -> Noun Det * Noun VP\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] Noun -> 'animal' *\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] NP -> Noun *\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] PP -> Noun * Det Noun VP\n",
      "|.  .  .  [-------->  .  .  .  .  .  .  .  .  .| [3:6] PP -> Noun Det Noun * VP\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] S  -> NP * VP\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .  .  .| [6:7] Verb -> 'be' *\n",
      "|.  .  .  .  .  .  [-->  .  .  .  .  .  .  .  .| [6:7] VP -> Verb * Adv PP\n",
      "|.  .  .  .  .  .  [-->  .  .  .  .  .  .  .  .| [6:7] VP -> Verb * Adj Conj Det Punt\n",
      "|.  .  .  .  .  [----->  .  .  .  .  .  .  .  .| [5:7] NP -> Noun Verb * Adj Punt\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .  .  .| [7:8] Adj -> 'ugly' *\n",
      "|.  .  .  .  .  .  [----->  .  .  .  .  .  .  .| [6:8] VP -> Verb Adj * Conj Det Punt\n",
      "|.  .  .  .  .  [-------->  .  .  .  .  .  .  .| [5:8] NP -> Noun Verb Adj * Punt\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .  .  .| [8:9] Conj -> 'than' *\n",
      "|.  .  .  .  .  .  [-------->  .  .  .  .  .  .| [6:9] VP -> Verb Adj Conj * Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .  .  .| [9:10] Det -> 'yours' *\n",
      "|.  .  .  .  .  .  [----------->  .  .  .  .  .| [6:10] VP -> Verb Adj Conj Det * Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  [-->  .  .  .  .| [10:11] Punt -> '!' * NP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] Noun -> 'i' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] NP -> Noun *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] PP -> Noun * Det Noun VP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] S  -> NP * VP\n",
      "|.  .  .  .  .  .  .  .  .  .  [-----]  .  .  .| [10:12] Punt -> '!' NP *\n",
      "|.  .  .  .  .  .  [-----------------]  .  .  .| [6:12] VP -> Verb Adj Conj Det Punt *\n",
      "|.  .  .  [--------------------------]  .  .  .| [3:12] PP -> Noun Det Noun VP *\n",
      "|.  .  .  .  .  [--------------------]  .  .  .| [5:12] S  -> NP VP *\n",
      "|.  [--------------------------------]  .  .  .| [1:12] VP -> Verb Adv PP *\n",
      "|[-----------------------------------]  .  .  .| [0:12] S  -> NP VP *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]  .  .| [12:13] Verb -> 'be' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->  .  .| [12:13] VP -> Verb * Adv PP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->  .  .| [12:13] VP -> Verb * Adj Conj Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [----->  .  .| [11:13] NP -> Noun Verb * Adj Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  [--]  .| [13:14] Adj -> 'sorry' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [----->  .| [12:14] VP -> Verb Adj * Conj Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-------->  .| [11:14] NP -> Noun Verb Adj * Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  .  [--]| [14:15] Punt -> '...' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-----------]| [11:15] NP -> Noun Verb Adj Punt *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [----------->| [11:15] S  -> NP * VP\n",
      "|.  .  .  .  .  .  .  .  .  .  [--------------]| [10:15] Punt -> '!' NP *\n",
      "|.  .  .  .  .  .  [--------------------------]| [6:15] VP -> Verb Adj Conj Det Punt *\n",
      "|.  .  .  [-----------------------------------]| [3:15] PP -> Noun Det Noun VP *\n",
      "|.  .  .  .  .  [-----------------------------]| [5:15] S  -> NP VP *\n",
      "|.  [-----------------------------------------]| [1:15] VP -> Verb Adv PP *\n",
      "|[============================================]| [0:15] S  -> NP VP *\n",
      "(S\n",
      "  (NP (Noun i))\n",
      "  (VP\n",
      "    (Verb do)\n",
      "    (Adv not)\n",
      "    (PP\n",
      "      (Noun notice)\n",
      "      (Det my)\n",
      "      (Noun animal)\n",
      "      (VP\n",
      "        (Verb be)\n",
      "        (Adj ugly)\n",
      "        (Conj than)\n",
      "        (Det yours)\n",
      "        (Punt ! (NP (Noun i) (Verb be) (Adj sorry) (Punt ...))))))) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our CFG using the lemmas got in the last step\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Noun | Noun Verb Adj Punt \n",
    "VP -> Verb Adv PP | Verb Adj Conj Det Punt\n",
    "PP -> Noun Det Noun VP\n",
    "Punt -> '!' NP | '...'\n",
    "Adv -> 'not'\n",
    "Adj -> 'ugly' | 'sorry'\n",
    "Det -> 'yours' | 'my'\n",
    "Noun -> 'i' | 'animal' | 'notice'\n",
    "Verb -> 'do' | 'be'\n",
    "Conj -> 'than'\n",
    "\"\"\")\n",
    "\n",
    "# Generate a syntactic parser be able to recognize the grammar\n",
    "parser = nltk.ChartParser(grammar, trace=1)\n",
    "print ('5. Syntactic analysis:\\n')\n",
    "for tree in parser.parse(lemmas):\n",
    "    print(tree,'\\n')\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Word tokenization -> Lemmatization -> POS tagger -> Syntactic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmas tagged: [('i', 'NNS'), ('do', 'VBP'), ('not', 'RB'), ('notice', 'VB'), ('my', 'PRP$'), ('animal', 'JJ'), ('be', 'VB'), ('ugly', 'RB'), ('than', 'IN'), ('yours', 'UH'), ('!', '.'), ('i', 'NN'), ('be', 'VB'), ('sorry', 'JJ'), ('...', ':')]\n"
     ]
    }
   ],
   "source": [
    "# Let's get the POS tags of each lemma:\n",
    "lemmas_tagged = nltk.pos_tag(lemmas)\n",
    "print (\"Lemmas tagged:\", lemmas_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntactic analysis:\n",
      "\n",
      "|.i .do.no.no.my.an.be.ug.th.yo.! .i .be.so....|\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] 'i'\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] 'do'\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .  .  .| [2:3] 'not'\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] 'notice'\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .  .  .| [4:5] 'my'\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] 'animal'\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .  .  .| [6:7] 'be'\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .  .  .| [7:8] 'ugly'\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .  .  .| [8:9] 'than'\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .  .  .| [9:10] 'yours'\n",
      "|.  .  .  .  .  .  .  .  .  .  [--]  .  .  .  .| [10:11] '!'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] 'i'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]  .  .| [12:13] 'be'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  [--]  .| [13:14] 'sorry'\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  .  [--]| [14:15] '...'\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] Noun -> 'i' *\n",
      "|[--]  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] NP -> Noun *\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] NP -> Noun * Verb Adj Punt\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] PP -> Noun * Det Noun VP\n",
      "|[-->  .  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:1] S  -> NP * VP\n",
      "|.  [--]  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] Verb -> 'do' *\n",
      "|.  [-->  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] VP -> Verb * Adv PP\n",
      "|.  [-->  .  .  .  .  .  .  .  .  .  .  .  .  .| [1:2] VP -> Verb * Adj Conj Det Punt\n",
      "|[----->  .  .  .  .  .  .  .  .  .  .  .  .  .| [0:2] NP -> Noun Verb * Adj Punt\n",
      "|.  .  [--]  .  .  .  .  .  .  .  .  .  .  .  .| [2:3] Adv -> 'not' *\n",
      "|.  [----->  .  .  .  .  .  .  .  .  .  .  .  .| [1:3] VP -> Verb Adv * PP\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] Noun -> 'notice' *\n",
      "|.  .  .  [--]  .  .  .  .  .  .  .  .  .  .  .| [3:4] NP -> Noun *\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] PP -> Noun * Det Noun VP\n",
      "|.  .  .  [-->  .  .  .  .  .  .  .  .  .  .  .| [3:4] S  -> NP * VP\n",
      "|.  .  .  .  [--]  .  .  .  .  .  .  .  .  .  .| [4:5] Det -> 'my' *\n",
      "|.  .  .  [----->  .  .  .  .  .  .  .  .  .  .| [3:5] PP -> Noun Det * Noun VP\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] Noun -> 'animal' *\n",
      "|.  .  .  .  .  [--]  .  .  .  .  .  .  .  .  .| [5:6] NP -> Noun *\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] PP -> Noun * Det Noun VP\n",
      "|.  .  .  [-------->  .  .  .  .  .  .  .  .  .| [3:6] PP -> Noun Det Noun * VP\n",
      "|.  .  .  .  .  [-->  .  .  .  .  .  .  .  .  .| [5:6] S  -> NP * VP\n",
      "|.  .  .  .  .  .  [--]  .  .  .  .  .  .  .  .| [6:7] Verb -> 'be' *\n",
      "|.  .  .  .  .  .  [-->  .  .  .  .  .  .  .  .| [6:7] VP -> Verb * Adv PP\n",
      "|.  .  .  .  .  .  [-->  .  .  .  .  .  .  .  .| [6:7] VP -> Verb * Adj Conj Det Punt\n",
      "|.  .  .  .  .  [----->  .  .  .  .  .  .  .  .| [5:7] NP -> Noun Verb * Adj Punt\n",
      "|.  .  .  .  .  .  .  [--]  .  .  .  .  .  .  .| [7:8] Adj -> 'ugly' *\n",
      "|.  .  .  .  .  .  [----->  .  .  .  .  .  .  .| [6:8] VP -> Verb Adj * Conj Det Punt\n",
      "|.  .  .  .  .  [-------->  .  .  .  .  .  .  .| [5:8] NP -> Noun Verb Adj * Punt\n",
      "|.  .  .  .  .  .  .  .  [--]  .  .  .  .  .  .| [8:9] Conj -> 'than' *\n",
      "|.  .  .  .  .  .  [-------->  .  .  .  .  .  .| [6:9] VP -> Verb Adj Conj * Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  [--]  .  .  .  .  .| [9:10] Det -> 'yours' *\n",
      "|.  .  .  .  .  .  [----------->  .  .  .  .  .| [6:10] VP -> Verb Adj Conj Det * Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  [-->  .  .  .  .| [10:11] Punt -> '!' * NP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] Noun -> 'i' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [--]  .  .  .| [11:12] NP -> Noun *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] NP -> Noun * Verb Adj Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] PP -> Noun * Det Noun VP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-->  .  .  .| [11:12] S  -> NP * VP\n",
      "|.  .  .  .  .  .  .  .  .  .  [-----]  .  .  .| [10:12] Punt -> '!' NP *\n",
      "|.  .  .  .  .  .  [-----------------]  .  .  .| [6:12] VP -> Verb Adj Conj Det Punt *\n",
      "|.  .  .  [--------------------------]  .  .  .| [3:12] PP -> Noun Det Noun VP *\n",
      "|.  .  .  .  .  [--------------------]  .  .  .| [5:12] S  -> NP VP *\n",
      "|.  [--------------------------------]  .  .  .| [1:12] VP -> Verb Adv PP *\n",
      "|[-----------------------------------]  .  .  .| [0:12] S  -> NP VP *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [--]  .  .| [12:13] Verb -> 'be' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->  .  .| [12:13] VP -> Verb * Adv PP\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [-->  .  .| [12:13] VP -> Verb * Adj Conj Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [----->  .  .| [11:13] NP -> Noun Verb * Adj Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  [--]  .| [13:14] Adj -> 'sorry' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  [----->  .| [12:14] VP -> Verb Adj * Conj Det Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-------->  .| [11:14] NP -> Noun Verb Adj * Punt\n",
      "|.  .  .  .  .  .  .  .  .  .  .  .  .  .  [--]| [14:15] Punt -> '...' *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [-----------]| [11:15] NP -> Noun Verb Adj Punt *\n",
      "|.  .  .  .  .  .  .  .  .  .  .  [----------->| [11:15] S  -> NP * VP\n",
      "|.  .  .  .  .  .  .  .  .  .  [--------------]| [10:15] Punt -> '!' NP *\n",
      "|.  .  .  .  .  .  [--------------------------]| [6:15] VP -> Verb Adj Conj Det Punt *\n",
      "|.  .  .  [-----------------------------------]| [3:15] PP -> Noun Det Noun VP *\n",
      "|.  .  .  .  .  [-----------------------------]| [5:15] S  -> NP VP *\n",
      "|.  [-----------------------------------------]| [1:15] VP -> Verb Adv PP *\n",
      "|[============================================]| [0:15] S  -> NP VP *\n",
      "(S\n",
      "  (NP (Noun i))\n",
      "  (VP\n",
      "    (Verb do)\n",
      "    (Adv not)\n",
      "    (PP\n",
      "      (Noun notice)\n",
      "      (Det my)\n",
      "      (Noun animal)\n",
      "      (VP\n",
      "        (Verb be)\n",
      "        (Adj ugly)\n",
      "        (Conj than)\n",
      "        (Det yours)\n",
      "        (Punt ! (NP (Noun i) (Verb be) (Adj sorry) (Punt ...))))))) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our CFG using the lemmas got in the last step\n",
    "grammar_POS = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> 'NNS' 'VBP' 'RB' | 'RB' 'IN' 'UH' Punt | 'NN' VP\n",
    "VP -> 'VB' 'PRP$' 'JJ' 'VB' NP |  'VB' 'JJ' Punt\n",
    "Punt -> '.' NP | ':'\n",
    "\"\"\")\n",
    "\n",
    "# Generate a syntactic parser be able to recognize the grammar\n",
    "parser = nltk.ChartParser(grammar, trace=1)\n",
    "print ('Syntactic analysis:\\n')\n",
    "for tree in parser.parse(lemmas):\n",
    "    print(tree,'\\n')\n",
    "    tree.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
