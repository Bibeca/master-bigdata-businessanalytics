{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network - First steps with Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have `Theano` installed, you have to install it like that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    conda install theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Theano "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_THREADING_LAYER=GNU\n"
     ]
    }
   ],
   "source": [
    "env MKL_THREADING_LAYER=GNU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic variable like scalar\n",
    "x = T.scalar('x')\n",
    "# Create another symbolic variable like the last variable squared\n",
    "y = x ** 2\n",
    "\n",
    "# None of these variables have a value, because they are symbolic\n",
    "# Evaluate the symbolic variable with x=2 \n",
    "y.eval({x : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(32.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two symbolic variables to make another symbolic variable more complex\n",
    "x = T.scalar('x')\n",
    "y = T.scalar('y')\n",
    "\n",
    "# Create the symbolic variable\n",
    "z = 2 * x + 3 * y\n",
    "# Evaluate the variable\n",
    "z.eval({x : 1, y : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Apart from `scalar`, there are many kind of symbolic variables:\n",
    "\n",
    "- `scalar`: a scalar variable.\n",
    "- `vector`: a vector variable.\n",
    "- `matrix`: a matrix 2x2 variable.\n",
    "- `row`: a row matrix.\n",
    "- `col`: a column matrix.\n",
    "- `tensor3`: a matrix 3x3 variable.\n",
    "- `tensor4`: a matrix 4x4 variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variable's evaluation with functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`eval()` method is not used. For variables evaluation, we are going to use the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(32.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the same example:\n",
    "x = T.scalar('x')\n",
    "y = T.scalar('y')\n",
    "\n",
    "# Create the symbolic variable\n",
    "z = 2 * x + 3 * y\n",
    "\n",
    "# Create the function\n",
    "f = theano.function(inputs = [x, y], outputs = z)\n",
    "f(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the Python standard functions like this:\n",
    "def sum_vars(a, b) :\n",
    "    return a + b\n",
    "\n",
    "z = sum_vars(x, y)\n",
    "f = theano.function(inputs = [x, y], outputs = z)\n",
    "f(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, another functions:\n",
    "y = cos(x)\n",
    "f = theano.function(inputs = [x], outputs = y)\n",
    "f(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conditional operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The standard conditional operations of Python are not used in `Theano`. For that, we are going to use the functions: `T.switch()` or `T.ifelse()`, and the Theano's comparation functions:\n",
    "\n",
    "- `T.lt()`\n",
    "- `T.le()`\n",
    "- `T.gt()`\n",
    "- `T.ge()`\n",
    "- `T.and_()`\n",
    "- `T.or_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabs(3) =  3.0\n",
      "Tabs(-3) =  3.0\n"
     ]
    }
   ],
   "source": [
    "# Let's create the absolute value function:\n",
    "x = T.scalar('x')\n",
    "\n",
    "y = T.switch(T.gt(x, 0), x, -x)\n",
    "\n",
    "Tabs = theano.function(inputs = [x], outputs = y)\n",
    "\n",
    "print(\"Tabs(3) = \", Tabs(3))\n",
    "print(\"Tabs(-3) = \", Tabs(-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `T.switch()` and `T.ifelse()` functions are the same, but `T.switch()` executes the two sentences before do the comparation. This makes the execute's time are higher than `T.ifelse()`. Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from theano.ifelse import ifelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time using switch is: 0.47379799999999994\n",
      "The time using ifelse is: 0.23953200000000008\n"
     ]
    }
   ],
   "source": [
    "# Create the variables\n",
    "a, b = T.scalars('a', 'b')\n",
    "x, y = T.matrices('x', 'y')\n",
    "\n",
    "# Create the conditionals sentences\n",
    "z_switch = T.switch(T.lt(a, b), T.mean(x), T.mean(y))\n",
    "z_ifelse = ifelse(T.lt(a, b), T.mean(x), T.mean(y))\n",
    "\n",
    "# Create the functions\n",
    "f_switch = theano.function(inputs = [a, b, x, y], outputs = z_switch)\n",
    "f_ifelse = theano.function(inputs = [a, b, x, y], outputs = z_ifelse)\n",
    "\n",
    "\n",
    "# Create data\n",
    "val1 = 0.\n",
    "val2 = 1.\n",
    "big_mat = np.ones((15000, 15000))\n",
    "\n",
    "# Execute with switch\n",
    "tic = time.clock()\n",
    "f_switch(val1, val2, big_mat, big_mat)\n",
    "print('The time using switch is:', (time.clock() - tic))\n",
    "\n",
    "# Execute with ifelse\n",
    "tic = time.clock()\n",
    "f_ifelse(val1, val2, big_mat, big_mat)\n",
    "print('The time using ifelse is:', (time.clock() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can observe, the time using `T.switch()` is the double than the time using `T.ifelse()`, because it execute both sentences before make the comparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Theano allows us indicate default values in the functions, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "x, y = T.scalars('x', 'y')\n",
    "\n",
    "z = x * y\n",
    "\n",
    "f = theano.function(inputs = [x, theano.In(y, value = 3)], outputs= z)\n",
    "print(f(10))\n",
    "print(f(10,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Shared variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the last examples, we don't indicate the value of each variable. However, there are times that indicate the variable's values is necessary. For that, `Theano` gives us the `shared variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Create the shared variable indicating its type\n",
    "x = theano.shared(np.array(1, dtype = theano.config.floatX))\n",
    "\n",
    "# Create a scalar\n",
    "A = T.scalar()\n",
    "\n",
    "# Create the function\n",
    "f = theano.function(inputs = [A], \n",
    "                    outputs = x, \n",
    "                    updates = {x : x - A}) # With 'updates', we indicate how update the shared value\n",
    "\n",
    "print(f(np.array(1)))\n",
    "print(x.get_value()) # Get value of shared variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can observe, first it returns the outputs values and after it updates the shared variables. This is so important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]]\n",
      "[[ 0.  1.]\n",
      " [ 2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# Let's see another example:\n",
    "x = theano.shared(np.array([[1, 2], [3, 4]], dtype = theano.config.floatX))\n",
    "A = T.matrix()\n",
    "f = theano.function(inputs = [A], outputs = x, updates = {x: x - A})\n",
    "\n",
    "print(f(np.array([[1, 1], [1, 1]])))\n",
    "print(x.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Matrices operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Theano is so efficient with the matrices operations, so, let's use it implementing the operation:\n",
    "$$ x = v \\times W + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.,  12.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = T.matrix()\n",
    "v = T.vector()\n",
    "b = T.vector()\n",
    "\n",
    "# Use the 'dot' function to make the matrices product\n",
    "x = T.dot(v, W) + b \n",
    "\n",
    "f = theano.function(inputs = [v, W, b], outputs = x)\n",
    "f([1,1], [[2,4],[3,5]], [2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A advantage of `Theano` is that it allows us make the gradient function to any function, without if the function is easier or more complex. For that, `Theano` gives us the `T.grad()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(20.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use a simple example\n",
    "x = T.scalar()\n",
    "y = x ** 2\n",
    "\n",
    "# y_grad = dy/dx\n",
    "y_grad = T.grad(y, x)\n",
    "\n",
    "# dy/dx = 2x\n",
    "y_grad.eval({x : 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Theano` for estimate a linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the step 0 \n",
      "\tw value: -0.8221021448232505 \n",
      "\tc value: 9.65237606595713 \n",
      "\twith a cost: 8.609280468825466\n",
      "In the step 1 \n",
      "\tw value: 0.36946501346751454 \n",
      "\tc value: 10.377253126985792 \n",
      "\twith a cost: 0.8795841520802172\n",
      "In the step 2 \n",
      "\tw value: 1.1757373611025022 \n",
      "\tc value: 10.215922512143077 \n",
      "\twith a cost: 0.07078109831206114\n",
      "In the step 3 \n",
      "\tw value: 1.6090842956416629 \n",
      "\tc value: 10.067365519899944 \n",
      "\twith a cost: 0.0009369119092350618\n",
      "In the step 4 \n",
      "\tw value: 1.8313476775888404 \n",
      "\tc value: 9.983782915080479 \n",
      "\twith a cost: 0.030648860518913155\n",
      "In the step 5 \n",
      "\tw value: 1.9440745550926066 \n",
      "\tc value: 9.940466962171929 \n",
      "\twith a cost: 0.0611925136029158\n",
      "In the step 6 \n",
      "\tw value: 2.0010878271859944 \n",
      "\tc value: 9.918442217430444 \n",
      "\twith a cost: 0.08055242368342794\n",
      "In the step 7 \n",
      "\tw value: 2.0299029720179305 \n",
      "\tc value: 9.907295804724823 \n",
      "\twith a cost: 0.09133845041495778\n",
      "In the step 8 \n",
      "\tw value: 2.044463909839546 \n",
      "\tc value: 9.901661385078475 \n",
      "\twith a cost: 0.09704531754099789\n",
      "In the step 9 \n",
      "\tw value: 2.0518215527305035 \n",
      "\tc value: 9.898814072596068 \n",
      "\twith a cost: 0.09999460478781151\n",
      "In the step 10 \n",
      "\tw value: 2.05553932890217 \n",
      "\tc value: 9.897375310906176 \n",
      "\twith a cost: 0.10150163265576044\n",
      "In the step 11 \n",
      "\tw value: 2.057417895348805 \n",
      "\tc value: 9.896648310757167 \n",
      "\twith a cost: 0.10226740740887102\n",
      "In the step 12 \n",
      "\tw value: 2.0583671212443893 \n",
      "\tc value: 9.896280962403315 \n",
      "\twith a cost: 0.1026554419251336\n",
      "In the step 13 \n",
      "\tw value: 2.0588467580671086 \n",
      "\tc value: 9.896095343935228 \n",
      "\twith a cost: 0.10285179229121742\n",
      "In the step 14 \n",
      "\tw value: 2.0590891149945434 \n",
      "\tc value: 9.896001552292718 \n",
      "\twith a cost: 0.10295107801500016\n"
     ]
    }
   ],
   "source": [
    "# Create the train data, for estimate the y = 2x + 10 linear regression\n",
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 2 * trX + np.random.randn(*trX.shape) * 0.5 + 10\n",
    "\n",
    "# Create the variables\n",
    "X = T.scalar()\n",
    "Y = T.scalar()\n",
    "\n",
    "# Create the model\n",
    "def model(X, w, c) :\n",
    "    return w * X + c\n",
    "\n",
    "# Create the variables to estimate\n",
    "w = theano.shared(np.asarray(0., dtype = theano.config.floatX))\n",
    "c = theano.shared(np.asarray(0., dtype = theano.config.floatX))\n",
    "y = model(X, w, c)\n",
    "\n",
    "# Create the cost functions like RMSE\n",
    "cost = T.mean(T.sqr(y - Y))\n",
    "\n",
    "# Create the gradient of each variable using the cost\n",
    "gradient_w = T.grad(cost = cost, wrt = w)\n",
    "gradient_c = T.grad(cost = cost, wrt = c)\n",
    "\n",
    "# Create the update function with the learned_rate\n",
    "learned_rate = 0.01\n",
    "updates = [[w, w - gradient_w * learned_rate], [c, c - gradient_c * learned_rate]]\n",
    "\n",
    "# Create the function to train the model\n",
    "train = theano.function(inputs = [X, Y],\n",
    "                        outputs = cost,\n",
    "                        updates = updates)\n",
    "\n",
    "\n",
    "# Train the model with 15 iterations:\n",
    "for i in range(15) :\n",
    "    for x, y in zip(trX, trY) :\n",
    "        cost_i = train(x, y)\n",
    "    \n",
    "    print('In the step', i, '\\n\\tw value:', w.get_value(), \n",
    "            '\\n\\tc value:', c.get_value(), '\\n\\twith a cost:', cost_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that with 15 iterations, the model is aproximated to the real values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
