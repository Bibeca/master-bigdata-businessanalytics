{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering and models selection - Variables transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the transformation which is used commonly during the data preprocessing in a machine learning model is the discretization. The discretization is make a ordinal feature using another kind of features (generally cuantitative). \n",
    "\n",
    "The discretization can be made using `cut()` function given by `pandas`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([good, good, good, medium, bad, good]\n",
      "Categories (3, object): [good < medium < bad], array([ 0.1905    ,  3.36666667,  6.53333333,  9.7       ]))\n"
     ]
    }
   ],
   "source": [
    "print(pd.cut(np.array([.2, 1.4, 2.5, 6.2, 9.7, 2.1]), # Data to discretizate\n",
    "             3,                                       # Number of groups to discretizate\n",
    "             labels = ['good', 'medium', 'bad'],      # Groups's labels\n",
    "             retbins = True))                         # Return de groups's definition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several methods to select the best division of a continue feature: the mean or the median, for example. Also, the Weight of Evidence (WoE) exists, which is defined like: \n",
    "\n",
    "$$WoE = \\ln \\frac{R_i(T)}{R_i(F)}$$\n",
    "\n",
    "Being $R_i(T)$ the true values rate of $i$ feature, and $R_i(F)$ the false values rate of $i$ feature. The WoE is not implemented by Python, we have to implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data   -> data\n",
    "# var    -> variable to estimate\n",
    "# target -> target\n",
    "def get_WoE(data, var, target) :\n",
    "    import pandas as pd\n",
    "    \n",
    "    crosstab = pd.crosstab(data[target], data[var])\n",
    "    \n",
    "    print('Getting the WoE value for the', var, 'variable:')\n",
    "    \n",
    "    for col in crosstab.columns :\n",
    "        if crosstab[col][1] == 0 :\n",
    "            print('  The WoE value for', col, '[', sum(crosstab[col]), '] is infinity.')\n",
    "        else :\n",
    "            WoE = np.log(float(crosstab[col][0]) / float(crosstab[col][1]))\n",
    "            print('  The WoE value for', col, '[', sum(crosstab[col]), '] is', WoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the WoE value for the Cat 1 variable:\n",
      "  The WoE value for False [ 3 ] is -0.69314718056\n",
      "  The WoE value for True [ 7 ] is 0.287682072452\n",
      "Getting the WoE value for the Cat 2 variable:\n",
      "  The WoE value for False [ 6 ] is -0.69314718056\n",
      "  The WoE value for True [ 4 ] is 1.09861228867\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'Value': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                   'Target': [True, True, False, True, True, False, True, False, False, False]})\n",
    "\n",
    "# Create two categorical variables depart from a continue variable\n",
    "data['Cat 1'] = data['Value'] > 3\n",
    "data['Cat 2'] = data['Value'] > 6\n",
    "\n",
    "# Get WoE of each categorical variable\n",
    "get_WoE(data, 'Cat 1', 'Target')\n",
    "get_WoE(data, 'Cat 2', 'Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in both cases, the WoE value below the threshold is -0.69, while the WoE value above the threshold is 0.28 in the first one and 1.09 in the second one. For that, the second configuration is better than the first one.\n",
    "\n",
    "The WoE value allows us identify the discretization capacity that a categorical variable has, but it say nothing above the set of variables. For that, we will use the IV method which will be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to explain three normalization methods, given by `scikit-learn`:\n",
    "\n",
    "- `MinMaxScaler` for a homogeneous variables.\n",
    "- `StandardScaler` for a normal variables.\n",
    "- `RobustScaler` for using the interquantile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler: [[ 0.83685545]\n",
      " [ 0.31276416]\n",
      " [ 1.        ]\n",
      " [ 0.        ]\n",
      " [ 0.85629755]\n",
      " [ 0.92307692]\n",
      " [ 0.9103973 ]\n",
      " [ 0.613694  ]\n",
      " [ 0.83601014]\n",
      " [ 0.42688081]]\n",
      "\n",
      "Standard: [[ 0.53347433]\n",
      " [-1.15836242]\n",
      " [ 1.06012673]\n",
      " [-2.16800692]\n",
      " [ 0.59623601]\n",
      " [ 0.81180876]\n",
      " [ 0.77087723]\n",
      " [-0.18692067]\n",
      " [ 0.53074556]\n",
      " [-0.78997861]]\n",
      "\n",
      "Robust: [[  9.98502247e-04]\n",
      " [ -1.23714428e+00]\n",
      " [  3.86420369e-01]\n",
      " [ -1.97603595e+00]\n",
      " [  4.69296056e-02]\n",
      " [  2.04692961e-01]\n",
      " [  1.74737893e-01]\n",
      " [ -5.26210684e-01]\n",
      " [ -9.98502247e-04]\n",
      " [ -9.67548677e-01]]\n"
     ]
    }
   ],
   "source": [
    "data = [35.6, -26.4, 54.9, -63.4, 37.9, 45.8, 44.3, 9.2, 35.5, -12.9]\n",
    "data = np.array(data).reshape(-1,1)\n",
    "\n",
    "minmax   = MinMaxScaler().fit(data)\n",
    "standard = StandardScaler().fit(data)\n",
    "robust   = RobustScaler().fit(data)\n",
    "\n",
    "print('MinMaxScaler:', minmax.transform(data))\n",
    "print('\\nStandard:', standard.transform(data))\n",
    "print('\\nRobust:', robust.transform(data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
