{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistical regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make a logistical regression with scikit-learn. This library have the `make_classification()` method to create a random dataset, and we are going to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets              import make_classification\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.metrics               import confusion_matrix\n",
    "from sklearn.model_selection       import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning confusion matrix:\n",
      "[[862  90]\n",
      " [ 97 826]]\n",
      "\n",
      "Testing confusion matrix:\n",
      "[[268  35]\n",
      " [ 28 294]]\n"
     ]
    }
   ],
   "source": [
    "# Create a random dataset for trainning\n",
    "x, y = make_classification(n_samples    = 2500, # size of dataset\n",
    "                           n_features   = 3,    # number of independients variables\n",
    "                           n_redundant  = 0,    # no redundant\n",
    "                           random_state = 1)    # between executions, dataset don't change\n",
    "\n",
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "# Create and fit the model\n",
    "classifier = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "# Predict the values\n",
    "y_train_pred = classifier.predict(x_train)\n",
    "y_test_pred = classifier.predict(x_test)\n",
    "\n",
    "# Get the confusion matrices\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print('Trainning confusion matrix:')\n",
    "print(cm_train)\n",
    "\n",
    "print('\\nTesting confusion matrix:')\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These confusion matrix show that the prediction is good, because the number of FN and FP is small. We can comparate the results and check if there is overfitting or not normalizing the confusion matrixs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized trainning confusion matrix:\n",
      "[[ 0.89885297  0.09825328]\n",
      " [ 0.10114703  0.90174672]]\n",
      "\n",
      "Testing confusion matrix:\n",
      "[[ 0.90540541  0.10638298]\n",
      " [ 0.09459459  0.89361702]]\n"
     ]
    }
   ],
   "source": [
    "print('Normalized trainning confusion matrix:')\n",
    "print(cm_train / sum(cm_train))\n",
    "print('\\nTesting confusion matrix:')\n",
    "print(cm_test / sum(cm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both matrix have the similar results, so we can say that there is not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
